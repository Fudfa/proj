{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GRU, Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the start and end date\n",
    "start_date = dt.datetime(2020,4,1)\n",
    "end_date = dt.datetime(2023,4,1)\n",
    "\n",
    "#loading from yahoo finance\n",
    "data = yf.download(\"GOOGL\",start_date, end_date)\n",
    "\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_columns',5)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting 80 percent data for training\n",
    "training_data_len = math.ceil(len(data) * .8)\n",
    "training_data_len \n",
    "\n",
    "#Splitting the dataset\n",
    "train_data = data[:training_data_len].iloc[:,:1] \n",
    "test_data = data[training_data_len:].iloc[:,:1]\n",
    "print(train_data.shape, test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Open Price values\n",
    "dataset_train = train_data.Open.values \n",
    "# Reshaping 1D to 2D array\n",
    "dataset_train = np.reshape(dataset_train, (-1,1)) \n",
    "dataset_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# scaling dataset\n",
    "scaled_train = scaler.fit_transform(dataset_train)\n",
    "\n",
    "print(scaled_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Open Price values\n",
    "dataset_test = test_data.Open.values \n",
    "# Reshaping 1D to 2D array\n",
    "dataset_test = np.reshape(dataset_test, (-1,1)) \n",
    "# Normalizing values between 0 and 1\n",
    "scaled_test = scaler.fit_transform(dataset_test) \n",
    "print(*scaled_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(50, len(scaled_train)):\n",
    "\tX_train.append(scaled_train[i-50:i, 0])\n",
    "\ty_train.append(scaled_train[i, 0])\n",
    "\tif i <= 51:\n",
    "\t\tprint(X_train)\n",
    "\t\tprint(y_train)\n",
    "\t\tprint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(50, len(scaled_test)):\n",
    "\tX_test.append(scaled_test[i-50:i, 0])\n",
    "\ty_test.append(scaled_test[i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is converted to Numpy array\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "#Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
    "print(\"X_train :\",X_train.shape,\"y_train :\",y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is converted to numpy array\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "#Reshaping\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0],1))\n",
    "print(\"X_test :\",X_test.shape,\"y_test :\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# adding RNN layers and dropout regularization\n",
    "regressor.add(SimpleRNN(units = 50, \n",
    "\t\t\t\t\t\tactivation = \"tanh\",\n",
    "\t\t\t\t\t\treturn_sequences = True,\n",
    "\t\t\t\t\t\tinput_shape = (X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50, \n",
    "\t\t\t\t\t\tactivation = \"tanh\",\n",
    "\t\t\t\t\t\treturn_sequences = True))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50,\n",
    "\t\t\t\t\t\tactivation = \"tanh\",\n",
    "\t\t\t\t\t\treturn_sequences = True))\n",
    "\n",
    "regressor.add( SimpleRNN(units = 50))\n",
    "\n",
    "# adding the output layer\n",
    "regressor.add(Dense(units = 1,activation='sigmoid'))\n",
    "\n",
    "# compiling RNN\n",
    "regressor.compile(optimizer = SGD(learning_rate=0.01,\n",
    "\t\t\t\t\t\t\t\tdecay=1e-6, \n",
    "\t\t\t\t\t\t\t\tmomentum=0.9, \n",
    "\t\t\t\t\t\t\t\tnesterov=True), \n",
    "\t\t\t\tloss = \"mean_squared_error\")\n",
    "\n",
    "# fitting the model\n",
    "regressor.fit(X_train, y_train, epochs = 20, batch_size = 2)\n",
    "regressor.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the model\n",
    "regressorLSTM = Sequential()\n",
    "\n",
    "#Adding LSTM layers\n",
    "regressorLSTM.add(LSTM(50, \n",
    "\t\t\t\t\treturn_sequences = True, \n",
    "\t\t\t\t\tinput_shape = (X_train.shape[1],1)))\n",
    "regressorLSTM.add(LSTM(50, \n",
    "\t\t\t\t\treturn_sequences = False))\n",
    "regressorLSTM.add(Dense(25))\n",
    "\n",
    "#Adding the output layer\n",
    "regressorLSTM.add(Dense(1))\n",
    "\n",
    "#Compiling the model\n",
    "regressorLSTM.compile(optimizer = 'adam',\n",
    "\t\t\t\t\tloss = 'mean_squared_error',\n",
    "\t\t\t\t\tmetrics = [\"accuracy\"])\n",
    "\n",
    "#Fitting the model\n",
    "regressorLSTM.fit(X_train, \n",
    "\t\t\t\ty_train, \n",
    "\t\t\t\tbatch_size = 1, \n",
    "\t\t\t\tepochs = 12)\n",
    "regressorLSTM.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the model\n",
    "regressorGRU = Sequential()\n",
    "\n",
    "# GRU layers with Dropout regularisation\n",
    "regressorGRU.add(GRU(units=50, \n",
    "\t\t\t\t\treturn_sequences=True,\n",
    "\t\t\t\t\tinput_shape=(X_train.shape[1],1),\n",
    "\t\t\t\t\tactivation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    "\n",
    "regressorGRU.add(GRU(units=50, \n",
    "\t\t\t\t\treturn_sequences=True,\n",
    "\t\t\t\t\tactivation='tanh'))\n",
    "\n",
    "regressorGRU.add(GRU(units=50, \n",
    "\t\t\t\t\treturn_sequences=True,\n",
    "\t\t\t\t\tactivation='tanh'))\n",
    "\n",
    "regressorGRU.add(GRU(units=50, \n",
    "\t\t\t\t\tactivation='tanh'))\n",
    "\n",
    "# The output layer\n",
    "regressorGRU.add(Dense(units=1,\n",
    "\t\t\t\t\tactivation='relu'))\n",
    "# Compiling the RNN\n",
    "regressorGRU.compile(optimizer=SGD(learning_rate=0.01, \n",
    "\t\t\t\t\t\t\t\tdecay=1e-7, \n",
    "\t\t\t\t\t\t\t\tmomentum=0.9, \n",
    "\t\t\t\t\t\t\t\tnesterov=False),\n",
    "\t\t\t\t\tloss='mean_squared_error')\n",
    "\n",
    "# Fitting the data\n",
    "regressorGRU.fit(X_train,y_train,epochs=20,batch_size=1)\n",
    "regressorGRU.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions with X_test data\n",
    "y_RNN = regressor.predict(X_test)\n",
    "y_LSTM = regressorLSTM.predict(X_test)\n",
    "y_GRU = regressorGRU.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling back from 0-1 to original\n",
    "y_RNN_O = scaler.inverse_transform(y_RNN) \n",
    "y_LSTM_O = scaler.inverse_transform(y_LSTM) \n",
    "y_GRU_O = scaler.inverse_transform(y_GRU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,figsize =(18,12),sharex=True, sharey=True)\n",
    "fig.suptitle('Model Predictions')\n",
    "\n",
    "#Plot for RNN predictions\n",
    "axs[0].plot(train_data.index[150:], train_data.Open[150:], label = \"train_data\", color = \"b\")\n",
    "axs[0].plot(test_data.index, test_data.Open, label = \"test_data\", color = \"g\")\n",
    "axs[0].plot(test_data.index[50:], y_RNN_O, label = \"y_RNN\", color = \"brown\")\n",
    "axs[0].legend()\n",
    "axs[0].title.set_text(\"Basic RNN\")\n",
    "\n",
    "#Plot for LSTM predictions\n",
    "axs[1].plot(train_data.index[150:], train_data.Open[150:], label = \"train_data\", color = \"b\")\n",
    "axs[1].plot(test_data.index, test_data.Open, label = \"test_data\", color = \"g\")\n",
    "axs[1].plot(test_data.index[50:], y_LSTM_O, label = \"y_LSTM\", color = \"orange\")\n",
    "axs[1].legend()\n",
    "axs[1].title.set_text(\"LSTM\")\n",
    "\n",
    "#Plot for GRU predictions\n",
    "axs[2].plot(train_data.index[150:], train_data.Open[150:], label = \"train_data\", color = \"b\")\n",
    "axs[2].plot(test_data.index, test_data.Open, label = \"test_data\", color = \"g\")\n",
    "axs[2].plot(test_data.index[50:], y_GRU_O, label = \"y_GRU\", color = \"red\")\n",
    "axs[2].legend()\n",
    "axs[2].title.set_text(\"GRU\")\n",
    "\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
